<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jonathan Clarkin</title>
    <description>Canadian Software Craftsman</description>
    <link>http://jclarkin.github.io</link>
    <atom:link href="http://jclarkin.github.io/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Running a Retrospective</title>
        <description>&lt;p&gt;This month, I ran my first retrospective for a different team at work. I’ve been participating in retrospectives run by my team mate and have wanted to try my hand at facilitating. When a different team approached me to host theirs, I was thrilled at the opportunity.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Preparation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I was made aware that this team had been having retrospectives… but they were more similar to a status meeting than to a voyage of discovery and improvement. A week before the event, I went to talk to the gang to witness their environment and see their interactions. I posed whether they had any working agreements, and soon discovered that most members were shy when asked to share their opinions aloud to the group. They were most comfortable ideating in private and collaborating only as necessary. This information helped me tailor which activities would be least disruptive for their retrospective.&lt;/p&gt;
&lt;p&gt;I proceeded to review the content of my two go-to books about retrospectives:&lt;/p&gt;
&lt;div style=&quot;text-align:center;&quot;&gt;
&lt;a href=&quot;http://www.amazon.com/gp/product/0977616649/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=390957&amp;amp;creativeASIN=0977616649&amp;amp;linkCode=as2&amp;amp;tag=breacsilos-20&amp;amp;linkId=B4G536I5PNV4EUWE&quot; target=&quot;_top&quot;&gt;&lt;img src=&quot;assets/q?_encoding=UTF8&amp;amp;ASIN=0977616649&amp;amp;Format=_SL110_&amp;amp;ID=AsinImage&amp;amp;MarketPlace=US&amp;amp;ServiceVersion=20070822&amp;amp;WS=1&amp;amp;tag=breacsilos-20&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p id=&quot;title&quot;&gt;&lt;a href=&quot;http://www.amazon.com/gp/product/0977616649/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=390957&amp;amp;creativeASIN=0977616649&amp;amp;linkCode=as2&amp;amp;tag=breacsilos-20&amp;amp;linkId=B4G536I5PNV4EUWE&quot; target=&quot;_top&quot;&gt;Agile Retrospectives: Making Good Teams Great&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;div style=&quot;text-align:center;&quot;&gt;
&lt;a href=&quot;http://www.amazon.com/gp/product/0596804172/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=390957&amp;amp;creativeASIN=0596804172&amp;amp;linkCode=as2&amp;amp;tag=breacsilos-20&amp;amp;linkId=GEDRG4IJLKKJIO2H&quot; target=&quot;_top&quot;&gt;&lt;img src=&quot;assets/q?_encoding=UTF8&amp;amp;ASIN=0596804172&amp;amp;Format=_SL110_&amp;amp;ID=AsinImage&amp;amp;MarketPlace=US&amp;amp;ServiceVersion=20070822&amp;amp;WS=1&amp;amp;tag=breacsilos-20&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p id=&quot;title&quot;&gt;&lt;a href=&quot;http://www.amazon.com/gp/product/0596804172/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=390957&amp;amp;creativeASIN=0596804172&amp;amp;linkCode=as2&amp;amp;tag=breacsilos-20&amp;amp;linkId=GEDRG4IJLKKJIO2H&quot; target=&quot;_top&quot;&gt;Gamestorming: A Playbook for Innovators, Rulebreakers, and Changemakers&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I selected a series of activities to get people talking, and to progress from individual contributions towards team decisions. With my outline in-hand, I was nervous but ready for the event.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Event&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I got to my room a half hour before the event. This gave me time to prep the room: move chairs to well distributed pattern, write the Agile Prime Directive on the whiteboard, get pens and cue cards out, display the agenda, and have poster board ready for categorization.&lt;/p&gt;
&lt;p&gt;In standard corporate fashion, the team trickled in fashionably late (first 5 minutes). From there, I began facilitating the retrospective.&lt;/p&gt;
&lt;p&gt;We began with “Set the Stage”. I recited the prime directive:&lt;br /&gt;
&lt;em&gt;&quot;Regardless of what we discover, we understand and truly believe that everyone did the best job they could, given what they knew at the time, their skills and abilities, the resources available, and the situation at hand.”&lt;/em&gt; --Norm Kerth &lt;/p&gt;
&lt;p&gt;I thanked everyone for willingly participating in the event, then we went over the agenda so that we all had a rough idea of the meeting’s pacing. Knowing that the crowd would not be forthcoming with opinions and participation, we started with a 1-2 Word Checkin activity as warm up. I was happy that we completed the circle with minimal protest.&lt;/p&gt;
&lt;p&gt;Keeping everyone comfortable in their chairs, the “Gather Data” stage began with the “Four L’s” activity. Each person acts as an individual contributor, reflecting on the sprint, and categorizing their experiences as Liked, Learned, Lacked, r Longed For. During and after the 15 minutes, people were to place their sticky notes onto the appropriate 4 poster boards. &lt;/p&gt;
&lt;p&gt;Thus we segued into a team activity: split into two groups and each group was to consolidate &amp;amp; summarize the data in 2 Ls (Liked and Lacked, or Learned and Longed For). Two presenters from each group were selected to share their discoveries with the team aloud.&lt;/p&gt;
&lt;p&gt;In the “Decide What to Do” phase, we moved to an activity that got everyone physically out of their seats and moving about: Dot Voting on the found themes each person deemed most important. With all votes tallied, it was easy to spot the top 4 themes for further investigation. I requested people to pair off with a team mate that they had not worked with for the Ls activity. Each pair was assigned a theme for further brainstorming, on potential next actions. Once again, a member was requested to present their discoveries to the whole team. Members of the team chose to champion an item, to be followed up within the next sprint.&lt;/p&gt;
&lt;p&gt;With the team aware of &lt;em&gt;Who&lt;/em&gt; would do &lt;em&gt;What&lt;/em&gt; by &lt;em&gt;When&lt;/em&gt;, we moved onto “Closing” activities. I thanked the team again for their participation, and requested that they leave me feedback on how the retrospective went. I handed out the sticky notes and pens, told them to leave the mess as is in the room for me to clean up, and exited so that they could converse in private.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aftermath&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After about 10 minutes, they emerged looking energetic and ready to tackle new problems. I was happy to see that effect. I had not realized the anterior affect of retrospectives; they are not just an opportunity to find ways to improve efficiency, but act as a team building event to strengthen communication pathways and working relationships.&lt;/p&gt;
&lt;p&gt;I returned to the room to put away the markers, stickers, and pens, to clean up the whiteboards and used stickies, and to reset the room to the state it had been prior to the fun we all just had. I looked over the feedback the team had left for me, and although it lacked any constructive criticism, it was filled with comments of people having a positive experience!  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Next Steps&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I learned a lot from facilitating a retrospective, and already have been asked to facilitate for other teams. I plan on trying out different activities, and will come prepared to record the data as the activities occur. I also plan on trying to keep that new-team energy flowing after the retrospective and into their next tasks. I feel that is a hard challenge when you are not part of the team and thus not involved with the time directly after the meeting.&lt;/p&gt;
&lt;p&gt;Having seen the event from the another perspective has given me greater appreciation of the benefits to retrospectives. I will now look forward to both participating in and facilitating these events in the months to come.&lt;/p&gt;
</description>
        <pubDate>Fri, 15 Aug 2014 07:41:25 -0400</pubDate>
        <link>http://jclarkin.github.io/running-a-retrospective/</link>
        <guid isPermaLink="true">http://jclarkin.github.io/running-a-retrospective/</guid>
      </item>
    
      <item>
        <title>Recent Reading - Agile Test Quadrants</title>
        <description>&lt;p&gt;A coworker recently shared with me &lt;a href=&quot;http://www.slideshare.net/ThoughtWorks/implementingcd-4131002155842phpapp02&quot; target=&quot;_blank&quot;&gt;this SlideShare presentation&lt;/a&gt; from ThoughtWorks.&lt;/p&gt;
&lt;p&gt;I had never seen the Agile Testing Quadrants model by Brian Marick, but I believe it will be useful in helping me communicate types of testing to the teams. There is currently an attitude forming that &quot;We can test everything via automation. Programmers can test it all, with more code&quot; which is fallacious, but change takes time. I am hoping that exposing people to different models and ideas will help accelerate understanding my perspective on the value of sapient testing.&lt;/p&gt;
&lt;p&gt;Here is the diagram I am referencing&lt;br /&gt;
&lt;img src=&quot;assets/Agile-Testing-Quadrants.png&quot; alt=&quot;Agile Testing Quadrants Model&quot; /&gt;&lt;/p&gt;
&lt;p&gt;I now have a new book added to my To Do list: &lt;a href=&quot;http://www.amazon.com/gp/product/0321534468/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=390957&amp;amp;creativeASIN=0321534468&amp;amp;linkCode=as2&amp;amp;tag=breacsilos-20&amp;amp;linkId=TCLVNWFBOX4B3W3T&quot;&gt;Agile Testing: A Practical Guide for Testers and Agile Teams&lt;/a&gt;&lt;img src=&quot;assets/ir?t=breacsilos-20&amp;amp;l=as2&amp;amp;o=1&amp;amp;a=0321534468&quot; width=&quot;1&quot; height=&quot;1&quot; border=&quot;0&quot; alt=&quot;&quot; style=&quot;border:none !important;margin:0!important;&quot; /&gt;. Hopefully it will add even more tools to my belt for both testing software, and teaching about testing to developers.&lt;/p&gt;
</description>
        <pubDate>Fri, 25 Jul 2014 07:13:18 -0400</pubDate>
        <link>http://jclarkin.github.io/recent-reading-agile-test-quadrants/</link>
        <guid isPermaLink="true">http://jclarkin.github.io/recent-reading-agile-test-quadrants/</guid>
      </item>
    
      <item>
        <title>Context Drive Testing - The Awakening</title>
        <description>&lt;p&gt;It has been a progressive unraveling of my assumptions and understanding of what is the &lt;a style=&quot;color:#047ac6;&quot; href=&quot;http://context-driven-testing.com/&quot;&gt;Context Driven&lt;/a&gt; movement going on in testing. When Selena Delesie first arrived at my work to help facilitate our learning of the possibilities a title of &quot;Software Tester&quot; could be, I stood deep in the valley. Now, I am nowhere near the peak of this steep climb up the mountain, but my view is less foggy.&lt;/p&gt;
&lt;p&gt;Much like the agile movement, the underlying goal is clear: &lt;strong&gt;apply critical thought&lt;/strong&gt;. Do not just swap out one process for another, or blindly trust the instructions given to you by a colleague. Your key job as a member of a team is to apply your own opinion + experiences + knowledge + wisdom + subjectivity. You don&#39;t have to just a cog in an industrial machine: your unique brain can add value to the team&#39;s goals.&lt;/p&gt;
&lt;p&gt;On the Twitterverse, I see an ongoing feud between two factions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the red corner: &lt;a style=&quot;color:#047ac6;&quot; href=&quot;https://twitter.com/RBCS&quot;&gt;Rex Black&lt;/a&gt; and the &lt;a style=&quot;color:#047ac6;&quot; href=&quot;http://www.istqb.org/&quot;&gt;ISTQB&lt;/a&gt; certified community&lt;/li&gt;
&lt;li&gt;In the blue corner: &lt;a style=&quot;color:#047ac6;&quot; href=&quot;https://twitter.com/jamesmarcusbach&quot;&gt;James Bach&lt;/a&gt; and the &lt;a style=&quot;color:#047ac6;&quot; href=&quot;http://context-driven-testing.com/&quot;&gt;CDT&lt;/a&gt; community&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-medium wp-image-130&quot; src=&quot;assets/rockem-sockem-robots1.jpg?w=300&quot; alt=&quot;rockem-sockem-robots1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;While researching the Tester schism, I came across this wonderful paper on the Schools of Software Testing by &lt;a style=&quot;color:#047ac6;&quot; href=&quot;http://pettichord.com/&quot; target=&quot;_blank&quot;&gt;Bret Pettichord&lt;/a&gt;:&lt;/p&gt;
&lt;ul style=&quot;color:#000000;&quot;&gt;
&lt;li&gt;Analytic: Testing as form of mathematics&lt;/li&gt;
&lt;li&gt;Standards: Testing should be predictable &amp;amp; repeatable, requiring little skill&lt;/li&gt;
&lt;li&gt;Quality: Testing adherence to processes and act as gate keepers&lt;/li&gt;
&lt;li&gt;Context-Driven: Testing as a human activity focused on finding and reporting on risks to value for stakeholders&lt;/li&gt;
&lt;li&gt;Agile: Testing as an automation-able dev activity to determine story completion and notify of change&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For me, having these five schools defined makes the discussion more clear. The ISTQB comes from a Standards and Quality family where there exists Best Practices and repeatable patterns to solve testing challenges. The CDT crew disagree, favouring Heuristics to help perform testing.&lt;/p&gt;
&lt;p&gt;Before moving on, lets address this question: What is the difference between &#39;Heuristic&#39; and &#39;Best Practices&#39; ? The term &#39;best practice&#39; implies that it is the recommended solution to a problem. It does not come with an asterisk beside it leading to the small-print legalese warning its users that &quot;Your Mileage May Vary&quot;. Instead, it sells the bearer a checklist of steps to follow to obtain the &#39;best results&#39; without heeding the context dependent variables. The term &#39;heuristic&#39; looks nearly the same: it provides a list of steps or terms to apply to a situation. The key is in the &lt;a style=&quot;color:#047ac6;&quot; href=&quot;http://en.wikipedia.org/wiki/Heuristic&quot; target=&quot;_blank&quot;&gt;definition of the word&lt;/a&gt;: &quot;a technique to solve problems that is not guaranteed to be optimal&quot;. There it is! By choosing a different word, the legal small-print needed for &quot;Best Practice&quot; has become the centerpiece of &quot;Heuristic&quot;.&lt;/p&gt;
&lt;p&gt;The CDT intentionally is choosing terminology to break from the mould and put the intelligent individual at the center of &quot;Testing&quot;. Much like &#39;agile&#39; it does not prescribe single solution to rule them all.&lt;br /&gt;
&lt;img class=&quot;size-medium wp-image-129 aligncenter&quot; src=&quot;assets/l_one_ring_gold_italian.jpg?w=300&quot; alt=&quot;l_one_ring_gold_italian&quot; width=&quot;300&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;
&lt;ul style=&quot;color:#000000;&quot;&gt;
&lt;li&gt;Does that mean there is no room for Analytic School of testing if you follow CDT? Nope! If your context suits mathematical metrics and proofs to decrease risk (and thus increase value), go for it!&lt;/li&gt;
&lt;li&gt;Does that mean there is no room for Agile School of testing? Nope. If devs authoring automated checks adds value to your project, go for it!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, I think both sides of the feud are fighting for the same goals: how to help testers be masters of their craft. Their approaches and terminology differ, let alone their visions of the future state of the craft... We just need to remain empathetic to all sides as that is a great way to learn from each other and to slowly affect change.&lt;/p&gt;
&lt;p&gt;For me, my vision s that we explorers strive to see past our logical fallacies and cognitive biases. We must &lt;strong&gt;apply critical thought&lt;/strong&gt; to our problems and not blindly rely on &quot;time tested best practices&quot;.&lt;/p&gt;
&lt;p&gt;.. and that is why I choose the label of Context Driven Tester.&lt;/p&gt;
</description>
        <pubDate>Mon, 26 May 2014 19:42:21 -0400</pubDate>
        <link>http://jclarkin.github.io/context-drive-testing-the-awakening/</link>
        <guid isPermaLink="true">http://jclarkin.github.io/context-drive-testing-the-awakening/</guid>
      </item>
    
      <item>
        <title>Classification of Software Features</title>
        <description>&lt;p&gt;I typically hear two categories for software features: internal and external. Occasionally, from the development side, I hear of a third option: deprecated. I am proposing a fourth category, that I often find in enterprise software that I would call &lt;em&gt;vestigial&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Here are my four categories defined:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;External Feature&lt;/strong&gt;: These are solutions for customer needs. They should produce value to the buyers of the software.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Internal Features&lt;/strong&gt;: These are solutions for the company that produces the software. They reduce costs of maintaining and improving the software.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deprecated Features&lt;/strong&gt;: These are solutions once targeted internally or externally that are known to no longer produce significant value to keep. The are technical debt that is clearly flagged for removal.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vestigial Features&lt;/strong&gt;: These are a mystery. They likely were once solutions to someone, or at least intended to be so. Their current value is unknown and cannot be flagged for deprecation. They are technical debt with no mitigation strategy.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A &lt;em&gt;vestigial feature&lt;/em&gt; is like the human appendix: maybe we don&#39;t need it anymore, but it remains part of our ecosystem. The tonsils were once vestigial until we learned more about them and determined their value.&lt;/p&gt;
&lt;p&gt;Does your enterprise software have many vestigial features? We can form a test strategy to determine their original intent, their current uses, and estimate their value.&lt;/p&gt;
</description>
        <pubDate>Fri, 25 Apr 2014 20:04:12 -0400</pubDate>
        <link>http://jclarkin.github.io/classification-of-software-features/</link>
        <guid isPermaLink="true">http://jclarkin.github.io/classification-of-software-features/</guid>
      </item>
    
      <item>
        <title>Heuristic for selecting a Trainer</title>
        <description>&lt;p&gt;When looking at a potential coach or teacher, I find myself often using the following criteria to help me make a selection.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Openness&lt;/strong&gt;: Do they expose their ideas and opinions in public forums? Do they allow discourse and feedback on their material, or is it a one-way channel?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prior Art&lt;/strong&gt;: Research material authored by the coach: articles, blog posts, videos, code, tweets, publications. Are ideas clearly expressed and compatible to your mode of learning?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bias&lt;/strong&gt;: Do they present multiple facets to ideas? Is there personal incentive for endorsing one idea over another?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interpersonal&lt;/strong&gt;: The &quot;Play nice with others&quot; factor. How to they behave in a group? Do they foster relationships and enable growth? Do they advocate for peers in their profession?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Referral&lt;/strong&gt;: Use your network of both people you know or online personas you respect and see if any of them approve or refer to the trainer or their material.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Experience&lt;/strong&gt;: Review the individual&#39;s listed skills, credentials, and experience. Can you trust them to bring authentic information that you believe applies to your needs?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is not a comprehensive lists (all models are flawed). What questions do you ask yourself when evaluating potential mentors, coaches, trainers, or teachers?&lt;/p&gt;
</description>
        <pubDate>Mon, 14 Apr 2014 10:08:42 -0400</pubDate>
        <link>http://jclarkin.github.io/heuristic-for-selecting-a-trainer/</link>
        <guid isPermaLink="true">http://jclarkin.github.io/heuristic-for-selecting-a-trainer/</guid>
      </item>
    
      <item>
        <title>JavaScript Unit Testing</title>
        <description>&lt;p&gt;&lt;i&gt;Note: The recommendations I make in this report are specific to the contextual needs of my current team. Your mileage may vary :)&lt;/i&gt;&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;The goal of this research was to determine tools and techniques to empower developers in unit testing JavaScript applications. The research discovered that there are three distinct aspects of JS unit testing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Authoring checks: the means of writing the unit tests&lt;/li&gt;
&lt;li&gt;Executing scripts: the frameworks that execute the checks&lt;/li&gt;
&lt;li&gt;Reporting: displaying the execution results in a consistent and valued format&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For authoring, the recommendation is to use the &lt;a href=&quot;http://chaijs.com/&quot;&gt;Chai.js&lt;/a&gt; library and to write checks in a behaviour driven development (BDD) format. For execution, the recommendation is to use &lt;a href=&quot;http://visionmedia.github.io/mocha/#reporters&quot;&gt;Mocha&lt;/a&gt; as it has the most versatility to integrate into an existing Continuous Integration (CI) system. For reporting, the recommendation is to either use &lt;a href=&quot;http://www.sonarqube.org/&quot;&gt;SonarQube&lt;/a&gt; if looking for tracking history and other code quality metrics, or to create a custom reporter that suits the team’s needs.&lt;/p&gt;
&lt;h2&gt;Authoring Checks&lt;/h2&gt;
&lt;p&gt;As is typical in the JavaScript world, given any one need there exists many similar libraries and frameworks to solve the problem. This remains true for unit test helpers. To further conflate selection, some libraries offer both authorship and execution in a single framework (see Table 1).&lt;/p&gt;
&lt;p&gt;The largest dichotomy between library selections is the supported writing style: do you want checks to be written as asserts (typically labelled at TDD for Test Driven Development) or as describing behaviour (BDD). Assertions are the more traditional pattern (see Code 1), but behavioural is more readable enabling increased visibility of risk to Product Owners and Business Analysts (see Code 2).&lt;/p&gt;
&lt;table style=&quot;border:1px solid black;&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;img src=&quot;assets/JSUT-1.png&quot; /&gt;&lt;br /&gt;
&lt;em&gt;Code Sample 1: TDD Style Unit Testing&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;table style=&quot;border:1px solid black;&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;img src=&quot;assets/JSUT-2.png&quot; /&gt;&lt;br /&gt;
&lt;em&gt;Code Sample 2: BDD Style Unit Testing&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The selection of libraries and frameworks is simplified by comparing these aspects (see Table 1).&lt;/p&gt;
&lt;table style=&quot;border:1px solid black;&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td width=&quot;126&quot;&gt;&lt;strong&gt;Name&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;&lt;strong&gt;TDD Style&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;&lt;strong&gt;BDD Style&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;116&quot;&gt;&lt;strong&gt;Authoring&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;133&quot;&gt;&lt;strong&gt;Execution&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td width=&quot;126&quot;&gt;&lt;strong&gt;Chai.js&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;116&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;133&quot;&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;126&quot;&gt;&lt;strong&gt;QUnit&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;116&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;133&quot;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;126&quot;&gt;&lt;strong&gt;Jasmine&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;116&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;133&quot;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;126&quot;&gt;&lt;strong&gt;Unit.js&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;116&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;133&quot;&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;126&quot;&gt;&lt;strong&gt;Mocha&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;116&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;133&quot;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;126&quot;&gt;&lt;strong&gt;Test Swarm&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;116&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;133&quot;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;126&quot;&gt;&lt;strong&gt;Buster.js&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;116&quot;&gt;Yes&lt;/td&gt;
&lt;td width=&quot;133&quot;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;126&quot;&gt;&lt;strong&gt;Intern.io&lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;124&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;116&quot;&gt;No&lt;/td&gt;
&lt;td width=&quot;133&quot;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Table 1: JavaScript Unit Test Frameworks Compared&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Basing a choice on the “&lt;a href=&quot;http://en.wikipedia.org/wiki/Single_responsibility_principle&quot;&gt;Single Responsibility Principle&lt;/a&gt;” a framework focused on authoring was recommended: &lt;strong&gt;Chai.js&lt;/strong&gt;. It is versatile, supporting both TDD and BDD coding styles. It is well supported online. Most importantly, checks written using it can easily be ported to another library if so desired.&lt;/p&gt;
&lt;h2&gt;Executing Scripts&lt;/h2&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;With authoring selected, the next aspect to be solved is execution of these unit test scripts. There are two primary scenarios for execution: developers verifying their programs and systems (continuous integration) checking for unexpected impacts to the system.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;To enable developers to verify their creations, keeping a simple workflow for execution is desired. Most Test Executors have a server based aspect (like running on a Node.js server), as well as browser based execution. The authoring of a browser executor should be intuitive for developers (see Code 3).&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;For integrating to a system, it must support command-line execution, and offer outputs that can be fed to a reporting solution.&lt;br /&gt;
&amp;nbsp;&lt;/p&gt;
&lt;table style=&quot;border:1px solid black;&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;img src=&quot;assets/JSUT-3.png&quot; /&gt;&lt;br /&gt;
&lt;em&gt;Code Sample 3: Mocha Test Executor&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For similar reasons as the selection of authoring tools, &lt;strong&gt;Mocha&lt;/strong&gt; is recommended. It is well supported, and it would easy to port a solution to another executor if ever needed. Also, it offers the most execution output options of the frameworks considered.&lt;/p&gt;
&lt;h2&gt;Reporting Results&lt;/h2&gt;
&lt;p&gt;Surprisingly, there are not a lot of Off-the-Shelf reporting tools for unit tests (or other automated checks) nor report output formats. There are generally two reporting formats with spotty support: &lt;a href=&quot;http://en.wikipedia.org/wiki/Test_Anything_Protocol&quot;&gt;TAP&lt;/a&gt; and &lt;a href=&quot;http://stackoverflow.com/questions/442556/spec-for-junit-xml-output&quot;&gt;XUnit&lt;/a&gt;. Similarly, for reporting tools, only these three options were found: &lt;a href=&quot;http://www.sonarqube.org/&quot;&gt;SonarQube&lt;/a&gt;, &lt;a href=&quot;http://sourceforge.net/projects/testlink/&quot;&gt;TestLink&lt;/a&gt;, and &lt;a href=&quot;http://sourceforge.net/projects/smolder/&quot;&gt;Smolder&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Both Smolder and TestLink are focused on content management of test specifications, plans, and requirements. SonarQube is focused on code analysis and reporting metrics that may indicate overall product quality. For reporting, if already using one of these tools, it is worth investigating the results of integrating JavaScript unit tests. However, it may be overkill for some teams and may be difficult to migrate to a different future solution if keeping the report history is important.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Since Mocha offers output in both TAP and XUnit, it could be sufficient to build a custom reporting tool that processes these outputs and displays the state of all checks. If the goal is to never leave checks failing, a custom reporter would be a better choice. It would be designed to only display information relevant to the team (see Image 1).&lt;br /&gt;
&amp;nbsp;&lt;/p&gt;
&lt;table style=&quot;border:1px solid black;&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;img src=&quot;assets/JSUT-4.png&quot; /&gt;&lt;br /&gt;
&lt;em&gt;Image 1: Custom Domain-based Unit Test Reporter&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
        <pubDate>Fri, 11 Apr 2014 11:10:40 -0400</pubDate>
        <link>http://jclarkin.github.io/javascript-unit-testing/</link>
        <guid isPermaLink="true">http://jclarkin.github.io/javascript-unit-testing/</guid>
      </item>
    
      <item>
        <title>Research Session - Reporting Outputs of Automation</title>
        <description>&lt;p&gt;There is an underwhelming quantity of test reporting options. The protocols for integration are few (&lt;a href=&quot;http://stackoverflow.com/questions/442556/spec-for-junit-xml-output&quot; target=&quot;_blank&quot;&gt;XUnit&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/Test_Anything_Protocol&quot; target=&quot;_blank&quot;&gt;TAP&lt;/a&gt;) and the few tools that I found are not focused on reporting.&lt;/p&gt;
&lt;p&gt;If adopting a reporting tool, I would recommend using &lt;a href=&quot;http://www.sonarqube.org/&quot; target=&quot;_blank&quot;&gt;SonarQube&lt;/a&gt;. If using this tool, then the report output best supported is XUnit.&lt;/p&gt;
&lt;p&gt;An alternative approach would be to build a custom reporting tool and dashboard, that reflects the team&#39;s Domain Model and surfaces only relevant information.&lt;/p&gt;
&lt;p&gt;Session notes below the fold…&lt;/p&gt;
&lt;p&gt;&lt;!--more--&gt;&lt;/p&gt;
&lt;div&gt;&lt;strong&gt;Mission&lt;/strong&gt;: Look into UT reporting formats and opportunities to integrate results from different frameworks&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Charter&lt;/strong&gt;:&lt;/div&gt;
&lt;div&gt;
&lt;ul&gt;
&lt;li&gt;Research outputs from Mocha test runner&lt;/li&gt;
&lt;li&gt;Research outputs from JUnit&lt;/li&gt;
&lt;li&gt;Find commonalities for producing a single report&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Session&lt;/strong&gt;:&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Start: March 24, 2014&lt;/li&gt;
&lt;li&gt;Learn: Read about the many default outputs of &lt;a href=&quot;http://visionmedia.github.io/mocha/#reporters&quot; target=&quot;_blank&quot;&gt;Mocha&lt;br /&gt;&lt;/a&gt;The key options appear to be TAP, JSON, DOC/HTML, XUnit
&lt;ul&gt;
&lt;li&gt;JSON output is clean, but not a defined spec to exist in other tools&lt;/li&gt;
&lt;li&gt;DOC/HTML: Functional for reporting, but not integratable with other tools&lt;/li&gt;
&lt;li&gt;TAP (Test Anything Protocol): Cool, this one is a spec and meant to allow cross-communication&lt;/li&gt;
&lt;li&gt;XUnit: The Mocha website does not offer any documentation on what this is... Needs further investigation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learn: XUnit. Looks like this Mocha option is &lt;a href=&quot;https://groups.google.com/forum/#!topic/nodejs/E3UgP58K3YU&quot; target=&quot;_blank&quot;&gt;the same&lt;/a&gt; as the default output from JUnit
&lt;ul&gt;
&lt;li&gt;Ownership of this spec is not clear. May be Apache, may be Surefire...&lt;/li&gt;
&lt;li&gt;Looks like a good starting point if only Mocha and JUnit reports need to be integrated&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learn: What TAP options are there
&lt;ul&gt;
&lt;li&gt;A Java TAP Producer exists for JUnit and TestNG called &lt;a href=&quot;http://tap4j.org/&quot; target=&quot;_blank&quot;&gt;tap4j&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/adrianh/tap-4763472&quot; target=&quot;_blank&quot;&gt;Good slides&lt;/a&gt; on TAP and trying to integrate small suites into a single reporting solution&lt;br /&gt;Potential integration platforms: Sonar, TestLink, Smolder&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Test Reporters
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.sonarqube.org/&quot; target=&quot;_blank&quot;&gt;Sonar&lt;/a&gt;: Most polished of the 3 options. Provides more than just script report execution, but also code coverage, code quality evaluation, and more&lt;br /&gt;Doesn&#39;t seem to &lt;a href=&quot;http://sonarqube.15.x6.nabble.com/Fwd-Sonar-with-Mocha-Unit-testing-td4999961.html&quot; target=&quot;_blank&quot;&gt;support TAP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://sourceforge.net/projects/testlink/&quot; target=&quot;_blank&quot;&gt;TestLink&lt;/a&gt;: Focused on being a CMS (Content Management System) for test cases and scenarios, with support for uploading script reports&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://sourceforge.net/projects/smolder/&quot; target=&quot;_blank&quot;&gt;Smolder&lt;/a&gt;: Similar to TestLink, but with less documentation. Looks more user-friendly, but has less support&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Read article &quot;&lt;a href=&quot;http://dailyjs.com/2013/10/21/tap/&quot; target=&quot;_blank&quot;&gt;Why Dont You use TAP?&lt;/a&gt;&quot;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 01 Apr 2014 08:34:09 -0400</pubDate>
        <link>http://jclarkin.github.io/research-session-reporting-outputs-of-automation/</link>
        <guid isPermaLink="true">http://jclarkin.github.io/research-session-reporting-outputs-of-automation/</guid>
      </item>
    
      <item>
        <title>Research Session - JS UT Experimentation</title>
        <description>&lt;p&gt;&lt;span style=&quot;line-height:1.5;&quot;&gt;Recommend starting with &lt;/span&gt;&lt;a style=&quot;line-height:1.5;&quot; href=&quot;http://chaijs.com/&quot; target=&quot;_blank&quot;&gt;Chai.js&lt;/a&gt;&lt;span style=&quot;line-height:1.5;&quot;&gt; + &lt;/span&gt;&lt;a style=&quot;line-height:1.5;&quot; href=&quot;http://visionmedia.github.io/mocha/&quot;&gt;Mocha&lt;/a&gt;&lt;span style=&quot;line-height:1.5;&quot;&gt;, and &lt;/span&gt;&lt;a style=&quot;line-height:1.5;&quot; href=&quot;http://sinonjs.org/&quot; target=&quot;_blank&quot;&gt;Sinon.js&lt;/a&gt;&lt;span style=&quot;line-height:1.5;&quot;&gt; for mocking when necessary. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;line-height:1.5;&quot;&gt;A lot of the test libraries available are similar, so it is hard to go wrong. Chai.js appears to be commonly used and also integrated into larger frameworks. Since Chai is just a test authoring library, there is still need for a tool to execute the tests. For current needs, Mocha has good support and a lot of reporting output options. At this point, the added benefits provided by theintern.io do not add immediate value for me, but transitioning to it from Mocha should not be difficult.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;line-height:1.5;&quot;&gt;Further analysis plans&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Look into Test Runner outputs and how they might integrate into JUnit reports&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Simplistic examples created during experimentation can be found on &lt;a href=&quot;https://github.com/jclarkin/javascript-test-frameworks&quot; target=&quot;_blank&quot;&gt;Github here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Session notes below the fold...&lt;/p&gt;
&lt;p&gt;&lt;!--more--&gt;&lt;/p&gt;
&lt;div&gt;&lt;strong&gt;Mission&lt;/strong&gt;: Attempt to create JSUT (Javascript Unit Test) using simple libraries&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Charter&lt;/strong&gt;:&lt;/div&gt;
&lt;div&gt;
&lt;ul&gt;
&lt;li&gt;Create some executable tests using &lt;a href=&quot;http://chaijs.com/&quot; target=&quot;_blank&quot;&gt;Chai.js&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Follow traditional JUnit TDD patterns rather than BDD&lt;/li&gt;
&lt;li&gt;(added) Explore BDD experiments as well&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Session&lt;/strong&gt;:&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Start: March 19, 2014&lt;/li&gt;
&lt;li&gt;Experiment: Attempted to figure out &lt;a href=&quot;http://chaijs.com/&quot; target=&quot;_blank&quot;&gt;Chai.js&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fail: could not solve how to run the tests&lt;/li&gt;
&lt;li&gt;Experiment: Moving on to &lt;a href=&quot;https://qunitjs.com/&quot; target=&quot;_blank&quot;&gt;QUnit&lt;/a&gt; to warm my experience&lt;/li&gt;
&lt;li&gt;Success: got a simple sample of QUnit tests and runner executing&lt;/li&gt;
&lt;li&gt;Discovery: Chai.js does not have a test runner. We need to pick one to execute the chai tests&lt;/li&gt;
&lt;li&gt;Experiment: Chai.js with Mocha as the test runner&lt;/li&gt;
&lt;li&gt;Fail: Having trouble setting it up.&lt;/li&gt;
&lt;li&gt;Learn: Found these &lt;a href=&quot;https://github.com/Bartvds/chai-tdd-plugins&quot; target=&quot;_blank&quot;&gt;cool chai.js plugins&lt;/a&gt; that could be useful: helpers for statistics, jquery, http processing, and more&lt;/li&gt;
&lt;li&gt;Learn: Found &lt;a href=&quot;https://gist.github.com/maicki/7781943&quot; target=&quot;_blank&quot;&gt;this article&lt;/a&gt; to help me out&lt;/li&gt;
&lt;li&gt;Success: After much initial confusion, I have successfully authored some simple tests that I can run via HTML in a browser&lt;/li&gt;
&lt;li&gt;Learn: Visit from &lt;a href=&quot;https://twitter.com/snocorp&quot; target=&quot;_blank&quot;&gt;@snocorp&lt;/a&gt; has convinced me that it is silly to ignore BDD due to historic corporate aversion to change&lt;br /&gt;
Increasing the charter to include BDD experimentation&lt;/li&gt;
&lt;li&gt;Experiment: Create a BDD version of the chai-mocha tests&lt;/li&gt;
&lt;li&gt;Fail: Trouble getting the &#39;throw&#39; scenario to work...&lt;br /&gt;
Trying a success and fail case to ensure my understanding...&lt;/li&gt;
&lt;li&gt;Success: Added test cases for both throw and not throw to ensure understanding&lt;/li&gt;
&lt;li&gt;Experiment: Setup a &lt;a href=&quot;http://jasmine.github.io/&quot; target=&quot;_blank&quot;&gt;Jasmine&lt;/a&gt; test suite (BDD library and runner combined)&lt;/li&gt;
&lt;li&gt;Success:
&lt;ul&gt;
&lt;li&gt;very easy to use&lt;/li&gt;
&lt;li&gt;nearly identical to the chai-mocha-bdd experiment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learn: Based on my initial research report, there exists &lt;a href=&quot;http://unitjs.com/&quot; target=&quot;_blank&quot;&gt;Unit.js&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;I misunderstood it with initial research&lt;/li&gt;
&lt;li&gt;It is a library that contains the following micro-libraries
&lt;ul&gt;
&lt;li&gt;Mocking via &lt;a href=&quot;http://sinonjs.org/&quot; target=&quot;_blank&quot;&gt;Sinon.js&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;BDD via &lt;a href=&quot;https://github.com/moll/js-must&quot; target=&quot;_blank&quot;&gt;Must.js&lt;/a&gt; + &lt;a href=&quot;https://github.com/visionmedia/should.js/&quot; target=&quot;_blank&quot;&gt;Should.js&lt;/a&gt; + &lt;a href=&quot;https://github.com/LearnBoost/expect.js/&quot; target=&quot;_blank&quot;&gt;Expect.js&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TDD via &lt;a href=&quot;http://nodejs.org/api/assert.html&quot; target=&quot;_blank&quot;&gt;Node assert&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;It does not have a Test Runner, but it recommends Mocha as a decent starting point&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Paused - End of workday&lt;/li&gt;
&lt;li&gt;Start: March 20, 2014&lt;/li&gt;
&lt;li&gt;Learn: Audit the &quot;theintern.io&quot; webinar
&lt;ul&gt;
&lt;li&gt;Good presentation&lt;/li&gt;
&lt;li&gt;An alternate Test Runner to mocha&lt;/li&gt;
&lt;li&gt;Supports JS tests and Selenium (may require setting up a Selenium Grid to communicate to)&lt;/li&gt;
&lt;li&gt;Easy integration to Saucelabs (which can work in a secured environment via a secured tunnel)&lt;/li&gt;
&lt;li&gt;Covered AJAX mocking using AMD and replacing the default map of loaders at Setup, and reverting at teardown&lt;/li&gt;
&lt;li&gt;Framework built with Dojo&lt;/li&gt;
&lt;li&gt;Chai for assertions&lt;/li&gt;
&lt;li&gt;Istanbul for Code coverage&lt;/li&gt;
&lt;li&gt;Need to research and better understand Test Reports/Outputs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learn: Attended OttawaJS Meetup
&lt;ul&gt;
&lt;li&gt;Confirmed that my research is on the right tools/libraries/frameworks&lt;/li&gt;
&lt;li&gt;Was recommended to look into &lt;a href=&quot;http://karma-runner.github.io/&quot; target=&quot;_blank&quot;&gt;Karma&lt;/a&gt; test runner (previously called Testacular)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Paused - End of workday&lt;/li&gt;
&lt;li&gt;Start: March 21, 2014&lt;/li&gt;
&lt;li&gt;Learn: Karma test runner
&lt;ul&gt;
&lt;li&gt;Looks as good for test running as the alternative so far&lt;/li&gt;
&lt;li&gt;Has nice automation abilities similar to &lt;a href=&quot;http://gruntjs.com/&quot; target=&quot;_blank&quot;&gt;Grunt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Requires &lt;a href=&quot;http://nodejs.org/&quot; target=&quot;_blank&quot;&gt;Node.js&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Explain: Create summary of research&lt;/li&gt;
&lt;li&gt;Share: Place learning material into a &lt;a href=&quot;https://github.com/jclarkin/javascript-test-frameworks&quot; target=&quot;_blank&quot;&gt;public repo&lt;/a&gt; for others to also learn from it&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 21 Mar 2014 15:18:08 -0400</pubDate>
        <link>http://jclarkin.github.io/research-session-js-ut-experimentation/</link>
        <guid isPermaLink="true">http://jclarkin.github.io/research-session-js-ut-experimentation/</guid>
      </item>
    
      <item>
        <title>Research Session - Javascript Unit Testing</title>
        <description>&lt;p&gt;&lt;strong&gt;Report Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Much like the rest of the Javascript ecosystem, there are a lot of options for any given problem and not a lot of community consensus&lt;/li&gt;
&lt;li&gt;There are two aspects of JS testing needing to be addressed: tools to test (libraries) and tools to report results (test runners)&lt;/li&gt;
&lt;li&gt;When selecting libraries, there are two style choices: &lt;a href=&quot;http://en.wikipedia.org/wiki/Test-driven_development&quot; target=&quot;_blank&quot;&gt;TDD&lt;/a&gt; (Test Driven Development) vs. &lt;a href=&quot;http://en.wikipedia.org/wiki/Behavior-driven_development&quot; target=&quot;_blank&quot;&gt;BDD&lt;/a&gt; (Behaviour Driven Development)&lt;br /&gt;
Historically, our company has been more comfortable with TDD&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://chaijs.com/&quot; target=&quot;_blank&quot;&gt;Chai.js&lt;/a&gt; is a TDD library that looks like a good place to begin learning and experimenting with test authoring&lt;/li&gt;
&lt;li&gt;Still not sure of pros/cons between test runners&lt;/li&gt;
&lt;li&gt;Further analysis plans
&lt;ul&gt;
&lt;li&gt;Follow up with this question to the &lt;a href=&quot;http://ottawajs.org/&quot; target=&quot;_blank&quot;&gt;OttawaJS&lt;/a&gt; community on March 20th&lt;/li&gt;
&lt;li&gt;Attend &lt;a href=&quot;http://www.sitepen.com/site/intern.html&quot;&gt;Webinar on theintern.io&lt;/a&gt; on March 20th&lt;/li&gt;
&lt;li&gt;Experiment with TDD library &lt;a href=&quot;http://chaijs.com/&quot; target=&quot;_blank&quot;&gt;Chai.js&lt;/a&gt; and its test runner&lt;/li&gt;
&lt;li&gt;Experiment with test runner &lt;a href=&quot;http://theintern.io/&quot; target=&quot;_blank&quot;&gt;theinter.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span style=&quot;line-height:1.5;&quot;&gt;Session notes below the fold...&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;!--more--&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mission&lt;/strong&gt;: To determine and select tools for Javascript test scripting&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Charter&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google search for tool options&lt;/li&gt;
&lt;li&gt;Explore theintern.io (mentioned by an awesome colleague)&lt;/li&gt;
&lt;li&gt;Compare QUnit vs. Jasmine (previous knowledge)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Recording of Session&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Found &lt;a href=&quot;http://stackoverflow.com/questions/300855/javascript-unit-test-tools-for-tdd&quot; target=&quot;_blank&quot;&gt;this StackOverflow post&lt;/a&gt; with a large list of tools. Looks a bit out of date, but is a good start.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://jasmine.github.io/&quot; target=&quot;_blank&quot;&gt;Jasmine&lt;/a&gt; supports &lt;a href=&quot;http://en.wikipedia.org/wiki/Behavior-driven_development&quot; target=&quot;_blank&quot;&gt;BDD&lt;/a&gt;. Comes with equivalent ideas to &lt;a href=&quot;http://hamcrest.org/JavaHamcrest/&quot; target=&quot;_blank&quot;&gt;Hamcrest Matchers&lt;/a&gt;. Our dev team has not yet successfully assimilated BDD, so this is not a strong incentive for adoption.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://qunitjs.com/&quot; target=&quot;_blank&quot;&gt;QUnit&lt;/a&gt; site has some good material on refactoring code to become scriptable. Pretty execution display as an HTML file. Not seeing the big picture on how this would work in a CI environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;If we are just looking for a library to make assertions easier (like JUnit) then bare-bones might be the best.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://chaijs.com/&quot; target=&quot;_blank&quot;&gt;Chai.js&lt;/a&gt; seems like a lightweight assertion library. Worth consideration for initial practice authoring testable code.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.browserswarm.com/&quot; target=&quot;_blank&quot;&gt;BrowserSwarm&lt;/a&gt; is very cool. But it is a commercial offering of &lt;a href=&quot;http://testswarm.signalr.net/&quot; target=&quot;_blank&quot;&gt;TestSwarm&lt;/a&gt;. TestSwarm is also cool. A tool where any device can register to the swarm to execute JS test files. The project does not look highly active.... Is this due to it being fairly stable or that people have found a different path?&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;This brings a key question to light: test execution and reporting methods. This is really going to be the key to valuable tests...&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;On to touch base with &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_unit_testing_frameworks#JavaScript&quot; target=&quot;_blank&quot;&gt;Wiki list of JS Test frameworks&lt;/a&gt;&lt;br /&gt;
To further explore: Unit.js, Mocha, Sinon.js&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Unit.js&quot; target=&quot;_blank&quot;&gt;Unit.js&lt;/a&gt; looks similar to Chai.js and Jasmine.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://visionmedia.github.io/mocha/&quot; target=&quot;_blank&quot;&gt;Mocha.js&lt;/a&gt; is not a library, but a framework. It runs on Node, and is popular amongst the OttawaJS presenters last year. Uses 4 libraries to offer Asserts and BDD notation in test cases (should.js, expect.js, chai.js, &amp;amp; better-assert). Comes with classic JUnit style before/after/beforeEach/afterEach. Pretty reporting to the console, or a variety of formats (TAP, JSON, CLI, HTML, XUnit, ...).&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Sinon.js is a library in the vein of Mockito. Looks handy... but too advanced for our current needs. Keep in mind if mocking topic comes up.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Onto look into &lt;a href=&quot;http://theintern.io&quot; target=&quot;_blank&quot;&gt;theintern.io&lt;/a&gt;, from Dave. He sent a webinar for March 20th (I&#39;ve signed up). Now on to exploring the site/examples.
&lt;ul&gt;
&lt;li&gt;Looks to provide Test Execution with test authoring. Uses chai.js for asserts and expect.js for behaviour. Looks similar to authoring JUnit tests, with BDD and TDD support. Examples of how to have it execute Selenium over remote. Examples of using &lt;a href=&quot;https://saucelabs.com/&quot; target=&quot;_blank&quot;&gt;SauceLabs&lt;/a&gt; for multi-platform testing (Saucelabs not available for intranet activities). Good &lt;a href=&quot;https://github.com/theintern/intern-tutorial&quot; target=&quot;_blank&quot;&gt;example of code here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Test running can be Node, your browser, SauceLabs, Selenium Grid&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://theintern.io&quot; target=&quot;_blank&quot;&gt;theintern.io&lt;/a&gt; seems the most promising at this point and worth deeper investigation (hands on experimentation).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Listened to the recent &lt;a href=&quot;http://hanselminutes.com/412/getting-started-with-javascript-unit-testing-with-jasmine-and-rushaine-mcbean&quot; target=&quot;_blank&quot;&gt;Hanselminutes podcast&lt;/a&gt; on Javascript UT. Focused on explaining Jasmine, and BDD. Was interesting and pointed out that there are add-ons for Jasmine to tackle specific JS things (like jQuery and ajax).&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 12 Mar 2014 11:11:49 -0400</pubDate>
        <link>http://jclarkin.github.io/research-session-javascript-unit-testing/</link>
        <guid isPermaLink="true">http://jclarkin.github.io/research-session-javascript-unit-testing/</guid>
      </item>
    
      <item>
        <title>Test Sessions - Research Sessions</title>
        <description>&lt;p&gt;My responsibilities include researching and investigating tools to help others test software. I was recently asked to investigate options for helping developers author Unit Tests for Javascript applications.&lt;/p&gt;
&lt;p&gt;While thinking about performing the investigation, it came to me that I was testing something: a domain of knowledge. And what is a good tool to record such testing? &lt;a href=&quot;http://en.wikipedia.org/wiki/Session-based_testing&quot;&gt;Test Sessions&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;So, I am experimenting with this idea. I gave thought to my mission, wrote up an initial charter of exploration ideas, and have begun recording my path through the internet and contacts to learn more on Javascript unit testing.  Once I wrap it up, I will likely have more charters to explore and can try my hand at my first test report to hand back to the person requesting this information :)&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Mar 2014 16:29:21 -0400</pubDate>
        <link>http://jclarkin.github.io/test-sessions-research-sessions/</link>
        <guid isPermaLink="true">http://jclarkin.github.io/test-sessions-research-sessions/</guid>
      </item>
    
  </channel>
</rss>